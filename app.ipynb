{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HlgX14h5VBEM"},"outputs":[],"source":["#modüller\n","import pandas as pd\n","import config\n","import numpy as np\n","from datetime import datetime, date, timedelta\n","import requests\n","import json\n","from IPython.display import HTML\n","import os\n","import webbrowser\n","from jinja2 import Environment, FileSystemLoader\n","import matplotlib.pyplot as plt\n","from dateutil.relativedelta import relativedelta"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7uR2MI3VBEd"},"outputs":[],"source":["#fonksiyonlar\n","\n","def fon_balances(t):\n","\n","    fon_balances = pd.read_csv(config.FON_BALANCES_PATH, sep=\";\", decimal=\",\")\n","\n","    fon_balances.index = pd.to_datetime(fon_balances[\"Tarih\"], format=\"%d.%m.%Y\")\n","    fon_balances.drop(\"Tarih\", axis=1, inplace=True)\n","    fon_balances = fon_balances.resample('D').ffill()\n","\n","    last_date = fon_balances.index.max().date()\n","\n","    t = pd.to_datetime(t, dayfirst=True)\n","    new_dates = pd.date_range(last_date + timedelta(days=1), t)\n","\n","    # Reindex the DataFrame with the new dates, forward filling values\n","    fon_balances = fon_balances.reindex(fon_balances.index.union(new_dates)).ffill()\n","    fon_balances.index.name = \"Tarih\"\n","\n","    return fon_balances\n","\n","def tcmb_fetcher(start_date, end_date, tickers=[\"TP.DK.USD.A.YTL-0\"]):\n","    \"\"\" Fetches data from the TCMB (Central Bank of Turkey) website using POST requests with predefined headers. It retrieves data for specific tickers within a given date range, processes the JSON response, and returns a DataFrame with the fetched data.\n","\n","    Parameters:\n","    - start_date: str, start date in the format \"dd-mm-yyyy\"\n","    - end_date: str, end date in the format \"dd-mm-yyyy\"\n","    - tickers: list of str, tickers to fetch data for\n","\n","    Returns:\n","    - pd.DataFrame: DataFrame containing the fetched data with dates as index and tickers as columns\n","    \"\"\"\n","    print(\"TCMB datası alınıyor...\")\n","    # Replace dots with underscores in the start_date and end_date if necessary\n","    if \".\" in start_date:\n","        start_date = start_date.replace(\".\", \"-\")\n","    if \".\" in end_date:\n","        end_date = end_date.replace(\".\", \"-\")\n","\n","    url = \"https://evds2.tcmb.gov.tr/EVDSServlet\"\n","\n","    headers = {\n","        'Accept': '*/*',\n","        'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7',\n","        'Connection': 'keep-alive',\n","        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n","        'Origin': 'https://evds2.tcmb.gov.tr',\n","        'Referer': 'https://evds2.tcmb.gov.tr/index.php?/evds/serieMarket',\n","        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',\n","        'X-Requested-With': 'XMLHttpRequest'\n","    }\n","\n","    sd = pd.to_datetime(start_date, format=\"%d-%m-%Y\")\n","    ed = pd.to_datetime(end_date, format=\"%d-%m-%Y\")\n","\n","    days = (ed - sd).days + 1  # include the end date in the range\n","    intervals = [(i, min(i + 20, days)) for i in range(0, days, 20)]\n","\n","    # Prepare ticker columns for the DataFrame\n","    ticker_columns = [ticker.replace('.', '_')[:-2] for ticker in tickers]\n","    tcmb_df = pd.DataFrame(index=pd.date_range(start=sd, end=ed, freq=\"D\"), columns=ticker_columns)\n","\n","    for ticker in tickers:\n","        for start, end in intervals:\n","            data = {\n","                'orderby': 'Tarih+desc',\n","                'thousand': '1',\n","                'decimal': '2',\n","                'frequency': 'Date',\n","                'aggregationType': 'avg',\n","                'formula': '0',\n","                'graphicType': '0',\n","                'skip': start,\n","                'take': end - start,\n","                'sort': 'Tarih#true',\n","                'select': ticker,\n","                'startDate': start_date,\n","                'endDate': end_date,\n","                'obsCountEnabled': '',\n","                'obsCount': '',\n","                'categories': '5863',\n","                'mongoAdresses': 'evds',\n","                'userId': '',\n","                'datagroupString': 'bie_dkdovytl',\n","                'dateFormatValue': 'dd-mm-yyyy',\n","                'customFormula': 'null',\n","                'excludedSeries': 'null'\n","            }\n","\n","            response = requests.post(url, headers=headers, data=data)\n","            response.raise_for_status()\n","            json_data = response.json()\n","\n","            if 'items' not in json_data:\n","                print(f\"Warning: No data found for interval {start} to {end}\")\n","                continue\n","\n","            d = pd.DataFrame(json_data[\"items\"])\n","            if d.empty:\n","                print(f\"Warning: DataFrame is empty for interval {start} to {end}\")\n","                continue\n","\n","            d.index = pd.to_datetime(d[\"Tarih\"], format=\"%d-%m-%Y\")\n","            d = d.drop(columns=[\"Tarih\", \"UNIXTIME\"])\n","            tcmb_df.update(d)\n","\n","    tcmb_df = tcmb_df.astype(float)\n","    tcmb_df.index.name = \"TARIH\"\n","    tcmb_df = tcmb_df.interpolate(method='linear', axis=0)\n","    print(\"TCMB datası başarıyla alındı.\")\n","    return tcmb_df\n","\n","def viop_fetcher(ticker, start_date, end_date):\n","    base_url = \"https://www.borsaistanbul.com/data/vadeli/viop_gecici_tmp_{}.csv\"\n","\n","    start_date = datetime.strptime(start_date, \"%d.%m.%Y\")\n","    end_date = datetime.strptime(end_date, \"%d.%m.%Y\")\n","    start_date = start_date.strftime(\"%Y-%m-%d\")\n","    end_date = end_date.strftime(\"%Y-%m-%d\")\n","    print(f\"VİOP datası alınıyor...\")\n","    # Generate the date range\n","    date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n","\n","    # Initialize an empty list to store results\n","    results = []\n","\n","    for d in date_range:\n","\n","        formatted_date = d.strftime('%Y%m%d')\n","        #print(f'{formatted_date} için veri çekiliyor.')\n","        url = base_url.format(formatted_date)\n","\n","        try:\n","            # Read the CSV data directly from the URL\n","            df = pd.read_csv(url, sep=';', encoding='latin1')\n","\n","            # Filter the DataFrame for the given ticker\n","            filtered_df = df[df['SOZLESME KODU'] == ticker]\n","\n","            # Check if there's a match and add the date and settlement price to the results\n","            if not filtered_df.empty:\n","                settlement_price = filtered_df['UZLASMA FIYATI'].values[0]\n","                results.append({'TARIH': d, ticker: settlement_price})\n","\n","        except Exception as e:\n","            print(f\"Error fetching data for date {formatted_date}: {e}\")\n","\n","    # Convert the results to a DataFrame\n","    result_df = pd.DataFrame(results)\n","\n","    # Set the 'TARIH' column as datetime and make it the index\n","    result_df['TARIH'] = pd.to_datetime(result_df['TARIH'])\n","    result_df.set_index('TARIH', inplace=True)\n","    result_df = result_df.resample(\"D\").asfreq()\n","    result_df[ticker] = pd.to_numeric(result_df[ticker], errors='coerce')\n","    result_df[ticker] = result_df[ticker].interpolate(method=\"linear\")\n","    print(\"VİOP datası başarıyla alındı.\")\n","    return result_df\n","\n","def tefas_fetcher(tarih):\n","    kaydedilenler = []\n","    baslangic_tarihi, bitis_tarihi = pd.to_datetime(tarih, format=\"%d.%m.%Y\")\n","\n","    periyotlar = pd.date_range(baslangic_tarihi, bitis_tarihi, freq=\"90D\")\n","    kalan_gun_sayisi = (bitis_tarihi - periyotlar[-1]).days\n","\n","    print(f\"{len(periyotlar)} periyot ve {kalan_gun_sayisi} kalan gün bulundu.\")\n","\n","    # Başlangıç ve bitiş tarihlerinin listelerini oluşturun\n","    baslangic_tarihleri = periyotlar[:-1].strftime(\"%d.%m.%Y\").tolist()\n","    bitis_tarihleri = (periyotlar[1:] - timedelta(days=1)).strftime(\"%d.%m.%Y\").tolist()\n","    # Kalan günleri ekleyin\n","    if kalan_gun_sayisi > 0:\n","        baslangic_tarihleri.append(periyotlar[-1].strftime(\"%d.%m.%Y\"))\n","        bitis_tarihleri.append(bitis_tarihi.strftime(\"%d.%m.%Y\"))\n","    else:\n","        baslangic_tarihleri = [tarih[0]]\n","        bitis_tarihleri = [tarih[1]]\n","\n","    for baslangic, bitis in zip(baslangic_tarihleri, bitis_tarihleri):\n","        print(f\"{baslangic} - {bitis} tarihleri arasındaki veriler çekiliyor...\")\n","\n","        url = config.TEFAS_URL\n","        essential_headers = {\n","            \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n","            \"Accept-Language\": \"en-US,en;q=0.9,tr-TR;q=0.8,tr;q=0.7\",\n","            \"Connection\": \"keep-alive\",\n","            \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n","            \"Referer\": \"https://www.tefas.gov.tr/TarihselVeriler.aspx\",\n","        }\n","\n","        data = {\n","            \"fontip\": \"YAT\",\n","            \"sfontur\": \"\",\n","            \"fonkod\": \"\",  # tüm kodları çeker\n","            \"fongrup\": \"\",\n","            \"bastarih\": baslangic,\n","            \"bittarih\": bitis,\n","            \"fonturkod\": \"\",\n","            \"fonunvantip\": \"\"\n","        }\n","\n","        response = requests.post(url, headers=essential_headers, data=data)\n","\n","        if response.status_code == 200:\n","            print(\"JSON dosyası uzak bilgisayardan başarıyla alındı...\")\n","            fon_data = response.json()\n","            dosya_adi = f\"{config.JSON_PATH}/{baslangic}-{bitis}_response_data.json\"\n","            with open(dosya_adi, \"w\") as outfile:\n","                json.dump(fon_data, outfile, indent=4)\n","            print(f\"{dosya_adi} kaydedildi.\")\n","            kaydedilenler.append(dosya_adi)\n","        else:\n","            print(f\"{baslangic}-{bitis} için JSON alma başarısız. Hata kodu: {response.status_code}\")\n","\n","    return kaydedilenler\n","\n","def merge_and_interpolate(df1, df2):\n","    # df1 ve df2'yi birleştir, df2'nin değerleri df1'e öncelik verir\n","    df_combined = df2.combine_first(df1)\n","\n","    # df_combined'a df1 ve df2'yi yeniden ekleyerek eksik tarihleri de tamamla\n","    df_final = pd.concat([df_combined, df1, df2]).groupby(level=0).first()\n","    df_final_interpolated = df_final.replace(0, np.nan).interpolate(method='linear')\n","\n","    return df_final_interpolated\n","\n","def update_price_db(guncel_datalar):\n","    \"\"\"tefas dataları indirilen jsonlarının yer aldığı dosyaların path'lerini alır ve price_db'yi günceller.\n","    tcmb ve viop dataları doğrudan dataframe olarak alınır ve price_db'ye eklenir.\n","    [kaydedilenler, tcmb_df, viop_df] şeklinde\n","    \"\"\"\n","\n","    try:\n","        prices = pd.read_csv(config.PRICE_DB_PATH, sep=\";\", decimal=\",\", parse_dates=['TARIH'], dayfirst=True)\n","        prices.set_index('TARIH', inplace=True)\n","        prices.index = pd.to_datetime(prices.index)\n","    except FileNotFoundError:\n","        print(f\"Hata: {config.PRICE_DB_PATH} dosyası bulunamadı.\")\n","        return\n","\n","    if guncel_datalar[0] is not False:\n","        for dosya in guncel_datalar[0]:\n","            try:\n","                print(f\"İşleniyor: {dosya}\")\n","                with open(dosya, \"r\") as f:\n","                    data = json.load(f)[\"data\"]\n","                    df = pd.DataFrame(data)\n","\n","                df = df.drop(columns=[\n","                    \"BORSABULTENFIYAT\", \"FONUNVAN\"\n","                ])\n","\n","                df[\"TARIH\"] = pd.to_datetime(df[\"TARIH\"].astype(np.int64), unit=\"ms\")\n","\n","                df = df.sort_values(by=[\"FONKODU\",\"TARIH\"])\n","\n","                df = df.pivot(index=\"TARIH\", columns=\"FONKODU\", values=\"FIYAT\")\n","\n","            except (ValueError, TypeError) as e:\n","                print(f\"Hata: '{dosya}' dosyası işlenirken hata oluştu: {e}\")\n","                continue\n","\n","            prices = merge_and_interpolate(prices, df)\n","\n","    if guncel_datalar[1] is not False:\n","        prices = merge_and_interpolate(prices, guncel_datalar[1])\n","\n","    if  guncel_datalar[2] is not False:\n","        prices = merge_and_interpolate(prices, guncel_datalar[2])\n","\n","    # buraya tefas fonları dışındaki varlıkların satılması sırasındaki fiyatları manuel olarak sell_value_price_db fonksiyonu ile güncellenmeli.\n","    prices.to_csv(config.PRICE_DB_PATH, sep=\";\", decimal=\",\")\n","    print(\"price_db.csv dosyası kaydedildi.\")\n","    return prices\n","\n","def hist_price_update(dir=config.JSON_PATH):\n","    print(f\"İşleniyor: {dir}\")\n","    try:\n","        prices = pd.read_csv(config.PRICE_DB_PATH, sep=\";\", decimal=\",\", parse_dates=['TARIH'], dayfirst=True)\n","        prices.set_index('TARIH', inplace=True)\n","        prices.index = pd.to_datetime(prices.index)\n","    except FileNotFoundError:\n","        print(f\"Hata: {config.PRICE_DB_PATH} dosyası bulunamadı.\")\n","        return\n","\n","    #loop through json file in the directory\n","    for file in os.listdir(dir):\n","\n","        if file.endswith(\".json\"):\n","            print(f\"İşleniyor: {file}\")\n","            with open(f\"{dir}/{file}\", \"r\") as f:\n","                data = json.load(f)[\"data\"]\n","                df = pd.DataFrame(data)\n","                df[\"TARIH\"] = pd.to_datetime(df[\"TARIH\"].astype(np.int64), unit=\"ms\")\n","                df = df.sort_values(by=[\"FONKODU\",\"TARIH\"])\n","                df = df.pivot(index=\"TARIH\", columns=\"FONKODU\", values=\"FIYAT\")\n","            prices = merge_and_interpolate(prices, df)\n","    prices.to_csv(config.PRICE_DB_PATH, sep=\";\", decimal=\",\")\n","\n","def generate_portfolio_db(fon_balances, currency='TRY', prices=None):\n","    \"\"\"\n","    Generates a portfolio database with various calculated fields.\n","\n","    Args:\n","        fon_balances (pd.DataFrame): DataFrame with fund balances.\n","        currency (str, optional): The currency for calculations ('TRY' or 'USD').\n","                                    Defaults to 'TRY'.\n","        prices (pd.DataFrame, optional): DataFrame with price data.\n","                                        If None, loads from config.PRICE_DB_PATH.\n","\n","    Returns:\n","        pd.DataFrame: The generated portfolio database.\n","    \"\"\"\n","\n","    if prices is None:\n","        prices = pd.read_csv(config.PRICE_DB_PATH, sep=\";\", decimal=\",\", parse_dates=['TARIH'], dayfirst=True)\n","        prices.set_index('TARIH', inplace=True)\n","        prices.index = pd.to_datetime(prices.index)\n","\n","    prices = prices.fillna(0)\n","\n","    if currency == 'USD':\n","        prices = prices.div(prices[\"TP_DK_USD_A_YTL\"], axis=0)\n","\n","    prices = prices[fon_balances.columns]\n","    prices = prices.loc[fon_balances.index]\n","\n","    prices = prices.add_suffix(\"_p\").fillna(0)\n","    fon_balances = fon_balances.add_suffix(\"_q\").fillna(0)\n","\n","    df = pd.concat([fon_balances, prices], axis=1)\n","    df.fillna(0, inplace=True)\n","\n","    # Calculate total value for each asset\n","    for col in df.columns:\n","        if col.endswith('_q'):\n","            base_name = col[:-2]\n","            p_col = base_name + '_p'\n","            v_col = base_name + '_v'\n","            if p_col in df.columns:\n","                df[v_col] = df[col] * df[p_col]\n","\n","    # Calculate portfolio value\n","    df[f'Portfolio_{currency}'] = df.filter(like='_v').sum(axis=1)\n","\n","    # Calculate price differences and profits\n","    for col in df.columns:\n","        if col.endswith('_p'):\n","            df[col[:-2] + '_diff'] = df[col].diff()\n","    for col in df.columns:\n","        if col.endswith('_diff'):\n","            df[col[:-5] + '_profit'] = df[col] * df[col[:-5] + '_q'].shift(1)\n","\n","    # Calculate portfolio differences and profits\n","    df[f\"Portfolio_{currency}_diff\"] = df[f\"Portfolio_{currency}\"].diff()\n","    df[f'Portfolio_Profit_{currency}'] = df.filter(like='_profit').sum(axis=1)\n","    df[f'Portfolio_Profit_{currency}_daily'] = df[f'Portfolio_Profit_{currency}'] / df[f'Portfolio_{currency}'].shift(1)\n","    df[f'Portfolio_Profit_{currency}_cum'] = df[f'Portfolio_Profit_{currency}'].cumsum()\n","\n","    # Calculate cash flow\n","    df[f\"CF_{currency}\"] = df[f\"Portfolio_{currency}_diff\"] - df[f\"Portfolio_Profit_{currency}\"]\n","    df[f\"CF_{currency}\"].iloc[0] = df[f\"Portfolio_{currency}\"].iloc[0]\n","\n","    return df\n","\n","def add_invested_capital(df, window_size, currency='TRY'):\n","    \"\"\"\n","    Adds a column for average invested capital over a given window.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","        window_size (int): The size of the rolling window.\n","        currency (str, optional): The currency code to use in column names.\n","                                 Defaults to \"TRY\".\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with the added column.\n","    \"\"\"\n","\n","    invested_capital = []\n","    for i in range(len(df)):\n","        if i + 1 < window_size:\n","            invested_capital.append(pd.NA)\n","        else:\n","            portfolio_window = df[f'Portfolio_{currency}'].iloc[i+1-window_size:i+1]\n","            cf_window = df[f'CF_{currency}'].iloc[i+1-window_size:i+1]\n","            combined_window = pd.concat([pd.Series([portfolio_window.iloc[0]]), cf_window.iloc[1:]])\n","            invested_capital.append(combined_window.cumsum().mean())\n","\n","    df[f'Invested_Capital_{currency}_{window_size}_avg'] = invested_capital\n","    return df\n","\n","def add_roic_column(df, window_size, currency='TRY'):\n","    \"\"\"\n","    Adds a column for ROIC over a given window.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame.\n","        window_size (int): The size of the rolling window.\n","        currency (str, optional): The currency code to use in column names.\n","                                 Defaults to \"TRY\".\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with the added column.\n","    \"\"\"\n","\n","    profit_cumsum = []\n","    for i in range(len(df)):\n","        if i + 1 < window_size:\n","            profit_cumsum.append(pd.NA)\n","        else:\n","            profit_window = df[f'Portfolio_Profit_{currency}'].iloc[i+1-window_size:i+1]\n","            profit_cumsum.append(profit_window.cumsum().iloc[-1])\n","\n","    column_name = f'Portfolio_Profit_{currency}_sum_{window_size}'\n","    df[column_name] = profit_cumsum\n","    df[f'Roic_{window_size}'] = df[column_name] / df[f'Invested_Capital_{currency}_{window_size}_avg']\n","    return df\n","\n","def roics(df, d, currency='TRY'):\n","    \"\"\"\n","    Calculates various ROIC metrics for a given DataFrame.\n","\n","    Args:\n","        df (pd.DataFrame): The input DataFrame containing financial data.\n","        d (str): A date string in the format YYYY-MM-DD.\n","        currency (str, optional): The currency code to use as a prefix in column names.\n","                             Defaults to \"TRY\".\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with calculated ROIC metrics.\n","    \"\"\"\n","\n","    df[f\"Invested_Capital_{currency}_cum\"] = df[f\"CF_{currency}\"].cumsum()\n","    df[f\"Invested_Capital_{currency}_avg\"] = df[f\"Invested_Capital_{currency}_cum\"].expanding().mean()\n","    df[\"ROIC\"] = df[f\"Portfolio_Profit_{currency}_cum\"] / df[f\"Invested_Capital_{currency}_avg\"]\n","\n","    df['days'] = range(len(df))\n","    df[\"ROIC_CAGR\"] = (1 + df[\"ROIC\"]) ** (365 / df[\"days\"]) - 1\n","\n","    df = add_invested_capital(df, 30, currency)\n","    df = add_roic_column(df, 30, currency)\n","\n","    df = add_invested_capital(df, 365, currency)\n","    df = add_roic_column(df, 365, currency)\n","\n","    days_passed = (pd.to_datetime(d) - pd.to_datetime(d).replace(month=1, day=1)).days\n","    df = add_invested_capital(df, days_passed, currency)\n","    df = add_roic_column(df, days_passed, currency)\n","\n","    return df\n","\n","def add_sharpe_column(df, window_size, currency='TRY'):\n","    # calculate daily pct changes from PPZ_p column\n","    df[\"PPZ_pct_change\"] = df[\"PPZ_p\"].pct_change()\n","     # calculate std of Portfolio_Profit_{currency}_daily\n","    df[f\"Portfolio_Profit_{currency}_std_{window_size}\"] = df[f\"Portfolio_Profit_{currency}_daily\"].rolling(window=window_size).std()\n","    # calculate excess return\n","    df[f\"Excess_Return_{currency}_{window_size}\"] = df[f\"Portfolio_Profit_{currency}_daily\"] - df[\"PPZ_pct_change\"]\n","    # calculate rolling avg and std of excess return\n","    df[f\"Excess_Return_{currency}_{window_size}_avg\"] = df[f\"Excess_Return_{currency}_{window_size}\"].rolling(window=window_size).mean()\n","    df[f\"Excess_Return_{currency}_{window_size}_std\"] = df[f\"Excess_Return_{currency}_{window_size}\"].rolling(window=window_size).std()\n","    # calculate Sharpe Ratio and multiply with sqrt(365) to annualize\n","    df[f\"Sharpe_Ratio_{currency}_{window_size}\"] = (df[f\"Excess_Return_{currency}_{window_size}_avg\"] / df[f\"Excess_Return_{currency}_{window_size}_std\"]) * np.sqrt(365)\n","\n","    #df.to_csv(\"df.csv\", sep=\";\", decimal=\",\")\n","    return df\n","\n","def format_percentages(df):\n","    def format_value(x):\n","        \"\"\"Formats a value as a percentage, handling NaN and infinite values.\"\"\"\n","        if pd.isna(x):  # Check for both pd.NA and np.nan\n","            return \"n/a\"\n","        elif not np.isfinite(x):  # Use np.isfinite to check for infinite values\n","            return \"Inf\"\n","        elif abs(x) < 0.01:\n","            return f\"{x * 100:.3f}%\"\n","        elif 0.01 <= abs(x) < 1:\n","            return f\"{x * 100:.2f}%\"\n","        else:\n","            return f\"{x * 100:.0f}%\"\n","\n","    return df.applymap(format_value)\n","\n","def generate_dates(d,t=10):\n","    #convert d string to datetime and substract 10 days\n","    d = pd.to_datetime(d, dayfirst=True) - timedelta(days=t-1)\n","    dates = pd.date_range(d, periods=t, freq='D')\n","    dates = dates.strftime(\"%d.%m.%Y\")\n","    #convert to list\n","    dates = dates.tolist()\n","    return dates\n","\n","def getiri_tab(date, currencies=['TRY']):\n","    \"\"\"\n","    Generates a list of HTML tables showing portfolio returns for different periods.\n","\n","    Args:\n","        date (str): The date for which to calculate returns (DD.MM.YYYY).\n","        currencies (list, optional): List of currencies to calculate for.\n","                                     Defaults to ['TRY'].\n","\n","    Returns:\n","        list: A list of tuples, each containing a title and an HTML table string.\n","    \"\"\"\n","\n","    fon_balances_data = fon_balances(date)  # Assuming fon_balances is defined elsewhere\n","    dataframes_with_titles = []\n","\n","    for currency in currencies:\n","        portfolio_db = generate_portfolio_db(fon_balances_data, currency=currency)\n","        roics_data = roics(portfolio_db, date, currency=currency)\n","        roics_data_plot = roics_data\n","        roics_data = format_percentages(roics_data)\n","\n","        # Select columns containing \"ROIC\" (case-insensitive)\n","        roicz = roics_data.columns[roics_data.columns.str.contains(\"ROIC\", case=False)].tolist()\n","\n","        # Manuel olarak bugünün tarihini girin (örneğin: \"31.05.2024\")\n","        today_str = \"31.05.2024\"\n","        today_date = datetime.strptime(today_str, '%d.%m.%Y')\n","\n","        months_dates = [\n","            (today_str if i == 0 else (today_date.replace(day=1) - relativedelta(months=i) - timedelta(days=1)).strftime('%d.%m.%Y'))\n","            for i in range(12)\n","        ]\n","        #reverse the list\n","        months_dates = months_dates[::-1]\n","\n","        roic_tab_months = roics_data.loc[months_dates, roicz]\n","\n","        # Daily data\n","        days_dates = generate_dates(date)  # Assuming generate_dates is defined elsewhere\n","        roicz_days = [f\"Portfolio_Profit_{currency}_daily\"] + roicz\n","        roic_tab_days = roics_data.loc[days_dates, roicz_days]\n","\n","        # Yearly data\n","        years_dates = [\"31.12.2020\", \"31.12.2021\", \"31.12.2022\", \"31.12.2023\", \"31.05.2024\"]\n","        roic_tab_years = roics_data.loc[years_dates, roicz].drop(\"Roic_30\", axis=1, errors='ignore')\n","\n","        # Drop rows with NA/NaN values in 'Roic_365'\n","        roics_data_plot_cleaned = roics_data_plot.dropna(subset=[\"Roic_365\"])\n","\n","        # Convert to float in case of any type issues\n","        roics_data_plot_cleaned[\"Roic_365\"] = roics_data_plot_cleaned[\"Roic_365\"].astype(float)\n","\n","        # plot style\n","        plt.style.use('seaborn-darkgrid')\n","        # Plotting the cleaned data\n","        plt.figure(figsize=(10, 6))\n","        plt.plot(roics_data_plot_cleaned.index, roics_data_plot_cleaned[\"Roic_365\"], label=\"ROIC\")\n","        plt.title(f\"ROIC_365 - {currency}\")\n","        plt.xlabel(\"Date\")\n","        plt.ylabel(\"ROIC\")\n","        plt.grid(True)\n","        plt.legend()\n","        plt.savefig(f\"roic_{currency}.png\")\n","        plt.close()\n","\n","        # generate html code for the plot\n","        plot_html = f\"<img src='roic_{currency}.png'>\"\n","\n","        # Add dataframes to the list\n","        dataframes_with_titles.extend([\n","            (f\"Son 10 Gün - {currency}\", roic_tab_days.to_html()),\n","            (f\"Ay Sonları - {currency}\", roic_tab_months.to_html()),\n","            (f\"Yıl Sonları - {currency}\", roic_tab_years.to_html()),\n","            (f\"Tarihsel ROIC - {currency}\", plot_html)\n","        ])\n","\n","    return dataframes_with_titles\n","\n","def risk_tab(date, currencies=['TRY']):\n","    \"\"\"\n","    Generates a list of HTML tables showing portfolio Sharpe ratios for different periods.\n","\n","    Args:\n","        date (str): The date for which to calculate returns (DD.MM.YYYY).\n","        currencies (list, optional): List of currencies to calculate for.\n","                                     Defaults to ['TRY'].\n","\n","    Returns:\n","        list: A list of tuples, each containing a title and an HTML table string.\n","    \"\"\"\n","\n","    fon_balances_data = fon_balances(date)  # Assuming fon_balances is defined elsewhere\n","    dataframes_with_titles = []\n","\n","    for currency in currencies:\n","        portfolio_db = generate_portfolio_db(fon_balances_data, currency=currency)\n","\n","        # Adding Sharpe Ratio columns to the portfolio_db\n","        portfolio_db = add_sharpe_column(portfolio_db, 30, currency)\n","        portfolio_db = add_sharpe_column(portfolio_db, 365, currency)\n","\n","        # Formatting the Sharpe Ratio columns as one decimal float\n","        portfolio_db[f\"Sharpe_Ratio_{currency}_30\"] = portfolio_db[f\"Sharpe_Ratio_{currency}_30\"].round(1)\n","        portfolio_db[f\"Sharpe_Ratio_{currency}_365\"] = portfolio_db[f\"Sharpe_Ratio_{currency}_365\"].round(1)\n","\n","        # Selecting columns containing \"Sharpe\" (case-insensitive)\n","        sharpe_cols = portfolio_db.columns[portfolio_db.columns.str.contains(\"Sharpe\", case=False)].tolist()\n","\n","        # Daily data\n","        days_dates = generate_dates(date)\n","        sharpe_tab_days = portfolio_db.loc[days_dates, sharpe_cols]\n","\n","        # Yearly data\n","        years_dates = [\"31.12.2020\", \"31.12.2021\", \"31.12.2022\", \"31.12.2023\", \"31.05.2024\"]\n","        sharpe_tab_years = portfolio_db.loc[years_dates, sharpe_cols]\n","\n","        # Monthly data\n","        today_str = \"31.05.2024\"\n","        today_date = datetime.strptime(today_str, '%d.%m.%Y')\n","\n","        months_dates = [\n","            (today_str if i == 0 else (today_date.replace(day=1) - relativedelta(months=i) - timedelta(days=1)).strftime('%d.%m.%Y'))\n","            for i in range(12)\n","        ]\n","        months_dates = months_dates[::-1]\n","        sharpe_tab_months = portfolio_db.loc[months_dates, sharpe_cols]\n","\n","        dataframes_with_titles.extend([\n","            (f\"Son 10 Gün - {currency}\", sharpe_tab_days.to_html()),\n","            (f\"Ay Sonları - {currency}\", sharpe_tab_months.to_html()),\n","            (f\"Yıl Sonları - {currency}\", sharpe_tab_years.to_html())\n","        ])\n","\n","    return dataframes_with_titles\n","\n","\n","#fonksiyonlar son"]},{"cell_type":"code","source":["#datafetch\n","#her türlü tarih girdisi formatı dd.mm.yyyy olmalıdır.\n","tarih = [\"29.05.2024\", \"31.05.2024\"]\n","tefas = tefas_fetcher(tarih)\n","tcmb = tcmb_fetcher(tarih[0], tarih[1], tickers=[\"TP.DK.USD.A.YTL-0\"])\n","viop = viop_fetcher(\"F_XU0300624\", tarih[0], tarih[1])\n","prices = update_price_db([tefas, tcmb, viop])"],"metadata":{"id":"1lD4b47fVBEr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByZSENLVVBEz"},"outputs":[],"source":["d = \"31.05.2024\"\n","dataframes_with_titles_getiri = getiri_tab(d, currencies=['TRY', 'USD'])\n","\n","dataframes_with_titles_risk = risk_tab(d, currencies=['TRY'])\n","\n","# Zaman damgasını al\n","timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')\n","\n","# Jinja2 ortamını oluştur ve şablonu yükle\n","env = Environment(loader=FileSystemLoader('.'))\n","template = env.get_template('template.html')\n","\n","# Şablonu doldur ve HTML dosyasını oluştur\n","html_content = template.render(getiri_tables=dataframes_with_titles_getiri,risk_tables=dataframes_with_titles_risk, timestamp=timestamp)\n","\n","# HTML içeriğini bir dosyaya yaz\n","with open('Portföy Performans Raporu.html', 'w', encoding=\"utf-8\") as file:\n","    file.write(html_content)\n","\n","# HTML dosyasını aç\n","webbrowser.open('Portföy Performans Raporu.html')\n"]},{"cell_type":"code","source":["#fonksiyonları çalıştır\n","fon_balances_data = fon_balances(\"31.05.2024\")\n","\n","portfolio_db = generate_portfolio_db(fon_balances_data, currency=\"TRY\")\n","d = add_sharpe_column(portfolio_db, 30, currency=\"TRY\")\n","#print last 5 columns\n","print(d.iloc[:,-2:])\n"],"metadata":{"id":"v2VggwscVBE4"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}